from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.sql.types import *

print("ğŸš€ Spark ì´ˆê¸°í™” ì¤‘...")

# Spark Session ìƒì„±
spark = SparkSession.builder \
    .appName("EcommerceRealTimeAnalytics") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0") \
    .master("local[*]") \
    .getOrCreate()

spark.sparkContext.setLogLevel("WARN")

print("âœ… Spark ì¤€ë¹„ ì™„ë£Œ!")

# Kafkaì—ì„œ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ ì½ê¸°
df = spark \
    .readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "localhost:9092") \
    .option("subscribe", "orders") \
    .option("startingOffsets", "latest") \
    .load()

# JSON ìŠ¤í‚¤ë§ˆ ì •ì˜
schema = StructType([
    StructField("order_id", StringType()),
    StructField("timestamp", StringType()),
    StructField("user_id", StringType()),
    StructField("product_id", StringType()),
    StructField("product_name", StringType()),
    StructField("price", IntegerType()),
    StructField("quantity", IntegerType()),
    StructField("ip_address", StringType()),
    StructField("payment_method", StringType())
])

# JSON íŒŒì‹± + timestampë¥¼ ì‹¤ì œ timestamp íƒ€ì…ìœ¼ë¡œ ë³€í™˜
orders = df.select(
    from_json(col("value").cast("string"), schema).alias("data")
).select("data.*") \
 .withColumn("timestamp", to_timestamp(col("timestamp")))

# ì´ ê¸ˆì•¡ ê³„ì‚°
orders_with_total = orders.withColumn(
    "total_price", 
    col("price") * col("quantity")
)

print("\n" + "=" * 80)
print("ğŸ”¥ Spark Streaming ì‹¤ì‹œê°„ ë¶„ì„ ì‹œì‘!")
print("=" * 80)

# ==========================================
# ë¶„ì„ 1: ìµœê·¼ 30ì´ˆê°„ ì¸ê¸° ìƒí’ˆ Top 5
# ==========================================
popular_products = orders_with_total \
    .withWatermark("timestamp", "30 seconds") \
    .groupBy(
        window(col("timestamp"), "30 seconds", "10 seconds"),
        col("product_name")
    ) \
    .agg(
        count("*").alias("ì£¼ë¬¸ìˆ˜"),
        sum("total_price").alias("ì´ë§¤ì¶œ")
    ) \
    .select(
        col("window.start").alias("ì‹œì‘ì‹œê°„"),
        col("window.end").alias("ì¢…ë£Œì‹œê°„"),
        col("product_name").alias("ìƒí’ˆëª…"),
        col("ì£¼ë¬¸ìˆ˜"),
        format_number(col("ì´ë§¤ì¶œ"), 0).alias("ì´ë§¤ì¶œ")
    ) \
    .orderBy(col("ì£¼ë¬¸ìˆ˜").desc())

# ==========================================
# ë¶„ì„ 2: ì˜ì‹¬ IP (ìµœê·¼ 1ë¶„ê°„ 10ê±´ ì´ìƒ)
# ==========================================
suspicious_ips = orders_with_total \
    .withWatermark("timestamp", "1 minute") \
    .groupBy(
        window(col("timestamp"), "1 minute", "30 seconds"),
        col("ip_address")
    ) \
    .agg(
        count("*").alias("ì£¼ë¬¸ìˆ˜"),
        sum("total_price").alias("ì´ê¸ˆì•¡"),
        collect_list("product_name").alias("êµ¬ë§¤ìƒí’ˆ")
    ) \
    .filter(col("ì£¼ë¬¸ìˆ˜") >= 10) \
    .select(
        col("window.start").alias("ì‹œì‘ì‹œê°„"),
        col("ip_address").alias("IPì£¼ì†Œ"),
        col("ì£¼ë¬¸ìˆ˜"),
        format_number(col("ì´ê¸ˆì•¡"), 0).alias("ì´ê¸ˆì•¡"),
        col("êµ¬ë§¤ìƒí’ˆ")
    )

# ==========================================
# ë¶„ì„ 3: ê³ ì•¡ ê±°ë˜ (50ë§Œì› ì´ìƒ)
# ==========================================
high_value = orders_with_total \
    .filter(col("total_price") >= 500000) \
    .select(
        col("timestamp").alias("ì‹œê°„"),
        col("order_id").alias("ì£¼ë¬¸ID"),
        col("product_name").alias("ìƒí’ˆëª…"),
        col("quantity").alias("ìˆ˜ëŸ‰"),
        format_number(col("total_price"), 0).alias("ê¸ˆì•¡"),
        col("ip_address").alias("IP")
    )

# ==========================================
# ì½˜ì†” ì¶œë ¥ í•¨ìˆ˜ ì •ì˜
# ==========================================

def print_header(batch_df, batch_id, title, emoji):
    """ë°°ì¹˜ë§ˆë‹¤ í—¤ë” ì¶œë ¥"""
    print("\n" + "=" * 80)
    print(f"{emoji} {title} (Batch #{batch_id})")
    print("=" * 80)

# ==========================================
# ì¿¼ë¦¬ 1: ì¸ê¸° ìƒí’ˆ Top 5 (10ì´ˆë§ˆë‹¤)
# ==========================================
print("\nğŸ“Š [ë¶„ì„ 1] ì¸ê¸° ìƒí’ˆ ìˆœìœ„ - ë§¤ 10ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸")
print("   â””â”€ ìµœê·¼ 30ì´ˆê°„ ê°€ì¥ ë§ì´ íŒ”ë¦° ìƒí’ˆì„ ì¶”ì í•©ë‹ˆë‹¤\n")

query1 = popular_products \
    .writeStream \
    .outputMode("complete") \
    .foreachBatch(lambda df, id: (
        print_header(df, id, "ì¸ê¸° ìƒí’ˆ Top 5", "ğŸ†"),
        df.show(5, truncate=False)
    )) \
    .trigger(processingTime='10 seconds') \
    .start()

# ==========================================
# ì¿¼ë¦¬ 2: ì˜ì‹¬ IP íƒì§€ (30ì´ˆë§ˆë‹¤)
# ==========================================
print("\nğŸš¨ [ë¶„ì„ 2] ì´ìƒ ê±°ë˜ íƒì§€ - ë§¤ 30ì´ˆë§ˆë‹¤ ì²´í¬")
print("   â””â”€ ê°™ì€ IPì—ì„œ 1ë¶„ ë‚´ 10ê±´ ì´ìƒ ì£¼ë¬¸í•œ ê²½ìš° ì•Œë¦¼\n")

query2 = suspicious_ips \
    .writeStream \
    .outputMode("append") \
    .foreachBatch(lambda df, id: (
        print_header(df, id, "âš ï¸  ë§¤í¬ë¡œ ì˜ì‹¬ IP ë°œê²¬!", "ğŸš¨") if df.count() > 0 else None,
        df.show(truncate=False) if df.count() > 0 else print("   âœ… ì˜ì‹¬ìŠ¤ëŸ¬ìš´ IP ì—†ìŒ")
    )) \
    .trigger(processingTime='30 seconds') \
    .start()

# ==========================================
# ì¿¼ë¦¬ 3: ê³ ì•¡ ê±°ë˜ ì‹¤ì‹œê°„ ì•Œë¦¼
# ==========================================
print("\nğŸ’° [ë¶„ì„ 3] ê³ ì•¡ ê±°ë˜ ëª¨ë‹ˆí„°ë§ - ì‹¤ì‹œê°„")
print("   â””â”€ 50ë§Œì› ì´ìƒ ê±°ë˜ ë°œìƒ ì‹œ ì¦‰ì‹œ ì•Œë¦¼\n")

def show_high_value(batch_df, batch_id):
    if batch_df.count() > 0:
        print("\n" + "=" * 80)
        print(f"ğŸ’³ ğŸ’° ê³ ì•¡ ê±°ë˜ ë°œìƒ! (Batch #{batch_id})")
        print("=" * 80)
        batch_df.show(truncate=False)
        print(f"ì´ {batch_df.count()}ê±´ì˜ ê³ ì•¡ ê±°ë˜")
    # countê°€ 0ì´ë©´ ì•„ë¬´ê²ƒë„ ì¶œë ¥ ì•ˆ í•¨

query3 = high_value \
    .writeStream \
    .outputMode("append") \
    .foreachBatch(show_high_value) \
    .start()

print("=" * 80)
print("âœ… ëª¨ë“  ë¶„ì„ ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...")
print("=" * 80)
print("\nğŸ’¡ Ctrl+Cë¥¼ ëˆŒëŸ¬ ì¢…ë£Œí•˜ì„¸ìš”\n")

# ìŠ¤íŠ¸ë¦¬ë° ìœ ì§€
try:
    query1.awaitTermination()
except KeyboardInterrupt:
    print("\n\n" + "=" * 80)
    print("ğŸ›‘ Spark Streaming ì¢…ë£Œ")
    print("=" * 80)
    spark.stop()